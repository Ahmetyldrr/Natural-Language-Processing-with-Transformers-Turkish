## Building a Review-Based QA System

# İnceleme Tabanlı Soru-Cevap Sistemi Oluşturma (Building a Review-Based QA System)

İnceleme tabanlı soru-cevap sistemleri, kullanıcıların ürünler hakkındaki incelemeleri okuyarak sorularına cevap bulmalarını sağlar. Bu sistemler, özellikle e-ticaret sitelerinde kullanıcıların ürünler hakkında daha fazla bilgi edinmelerine yardımcı olur.

## Veri Kümesi (Dataset)

Bu örnekte, SubjQA veri kümesi kullanılmıştır. Bu veri kümesi, 6 farklı kategoride (TripAdvisor, Restaurants, Movies, Books, Electronics ve Grocery) ürünler hakkında incelemeler ve bu incelemelere bağlı sorular içerir.

```python
from datasets import get_dataset_config_names
domains = get_dataset_config_names("subjqa")
print(domains)  # ['books', 'electronics', 'grocery', 'movies', 'restaurants', 'tripadvisor']
```

Bu kod, SubjQA veri kümesinin kategorilerini yazdırır.

*   `get_dataset_config_names("subjqa")`: Bu fonksiyon, "subjqa" veri kümesinin kategorilerini döndürür.

## Veri Kümesinin Yüklenmesi (Loading the Dataset)

Veri kümesini yüklemek için `load_dataset()` fonksiyonu kullanılır.

```python
from datasets import load_dataset
subjqa = load_dataset("subjqa", name="electronics")
```

Bu kod, SubjQA veri kümesinin "electronics" kategorisini yükler.

*   `load_dataset("subjqa", name="electronics")`: Bu fonksiyon, "subjqa" veri kümesinin "electronics" kategorisini yükler.

## Veri Kümesinin İncelenmesi (Exploring the Dataset)

Veri kümesi yüklendikten sonra, içerdiği sütunlar ve satırlar incelenebilir.

```python
import pandas as pd
dfs = {split: dset.to_pandas() for split, dset in subjqa.flatten().items()}
for split, df in dfs.items():
    print(f"Number of questions in {split}: {df['id'].nunique()}")
```

Bu kod, veri kümesinin her bir bölümündeki (train, test, validation) soru sayısını yazdırır.

*   `subjqa.flatten()`: Bu fonksiyon, veri kümesinin iç içe geçmiş sütunlarını düzleştirir.
*   `to_pandas()`: Bu fonksiyon, veri kümesini Pandas DataFrame'e dönüştürür.
*   `nunique()`: Bu fonksiyon, bir sütundaki benzersiz değerlerin sayısını döndürür.

## Soru-Cevap Modelinin Oluşturulması (Building the QA Model)

Soru-cevap modeli oluşturmak için Transformers kütüphanesinden yararlanılır.

```python
from transformers import AutoTokenizer, AutoModelForQuestionAnswering
model_ckpt = "deepset/minilm-uncased-squad2"
tokenizer = AutoTokenizer.from_pretrained(model_ckpt)
model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)
```

Bu kod, MiniLM modelini ve tokenizer'ı yükler.

*   `AutoTokenizer.from_pretrained(model_ckpt)`: Bu fonksiyon, model için tokenizer'ı yükler.
*   `AutoModelForQuestionAnswering.from_pretrained(model_ckpt)`: Bu fonksiyon, soru-cevap modeli için MiniLM modelini yükler.

## Soru-Cevap Modelinin Kullanılması (Using the QA Model)

Soru-cevap modeli, bir soru ve içerik (context) verildiğinde cevabı tahmin etmek için kullanılır.

```python
question = "How much music can this hold?"
context = """An MP3 is about 1 MB/minute, so about 6000 hours depending on file size."""
inputs = tokenizer(question, context, return_tensors="pt")
outputs = model(**inputs)
```

Bu kod, soru ve içerik için girdi tensörlerini oluşturur ve modeli çalıştırır.

*   `tokenizer(question, context, return_tensors="pt")`: Bu fonksiyon, soru ve içerik için girdi tensörlerini oluşturur.
*   `model(**inputs)`: Bu satır, modeli girdi tensörleri ile çalıştırır.

## Cevabın Çıkarılması (Extracting the Answer)

Modelin çıktısından cevabı çıkarmak için start ve end logit değerleri kullanılır.

```python
start_logits = outputs.start_logits
end_logits = outputs.end_logits
start_idx = torch.argmax(start_logits)
end_idx = torch.argmax(end_logits) + 1
answer_span = inputs["input_ids"][0][start_idx:end_idx]
answer = tokenizer.decode(answer_span)
print(f"Question: {question}")
print(f"Answer: {answer}")
```

Bu kod, start ve end logit değerlerini kullanarak cevabı çıkarır.

*   `torch.argmax(start_logits)`: Bu fonksiyon, start logit değerlerinin en yüksek olduğu indeksi döndürür.
*   `torch.argmax(end_logits) + 1`: Bu fonksiyon, end logit değerlerinin en yüksek olduğu indeksi döndürür ve 1 ekler.
*   `tokenizer.decode(answer_span)`: Bu fonksiyon, cevap span'ını decode eder.

## Haystack Kütüphanesinin Kullanılması (Using the Haystack Library)

Haystack kütüphanesi, soru-cevap sistemleri oluşturmak için kullanılır.

```python
from haystack.document_store.elasticsearch import ElasticsearchDocumentStore
document_store = ElasticsearchDocumentStore(return_embedding=True)
```

Bu kod, ElasticsearchDocumentStore'u oluşturur.

*   `ElasticsearchDocumentStore(return_embedding=True)`: Bu fonksiyon, ElasticsearchDocumentStore'u oluşturur ve embedding döndürmeyi etkinleştirir.

## Retriever ve Reader'ın Oluşturulması (Creating the Retriever and Reader)

Retriever ve reader, soru-cevap sisteminin temel bileşenleridir.

```python
from haystack.retriever.sparse import ElasticsearchRetriever
es_retriever = ElasticsearchRetriever(document_store=document_store)
from haystack.reader.farm import FARMReader
reader = FARMReader(model_name_or_path=model_ckpt, progress_bar=False)
```

Bu kod, ElasticsearchRetriever ve FARMReader'ı oluşturur.

*   `ElasticsearchRetriever(document_store=document_store)`: Bu fonksiyon, ElasticsearchRetriever'ı oluşturur.
*   `FARMReader(model_name_or_path=model_ckpt, progress_bar=False)`: Bu fonksiyon, FARMReader'ı oluşturur.

## Soru-Cevap Sisteminin Oluşturulması (Building the QA System)

Soru-cevap sistemi, retriever, reader ve pipeline'ı bir araya getirerek oluşturulur.

```python
from haystack.pipeline import ExtractiveQAPipeline
pipe = ExtractiveQAPipeline(reader, es_retriever)
```

Bu kod, ExtractiveQAPipeline'ı oluşturur.

*   `ExtractiveQAPipeline(reader, es_retriever)`: Bu fonksiyon, ExtractiveQAPipeline'ı oluşturur.

## Soru-Cevap Sisteminin Kullanılması (Using the QA System)

Soru-cevap sistemi, bir soru verildiğinde cevabı tahmin etmek için kullanılır.

```python
query = "Is it good for reading?"
item_id = "B0074BW614"
preds = pipe.run(query=query, top_k_retriever=3, top_k_reader=3, filters={"item_id": [item_id], "split": ["train"]})
```

Bu kod, soru-cevap sistemini kullanarak cevabı tahmin eder.

*   `pipe.run(query=query, top_k_retriever=3, top_k_reader=3, filters={"item_id": [item_id], "split": ["train"]})`: Bu fonksiyon, soru-cevap sistemini çalıştırır.

---

## Improving Our QA Pipeline

# QA Pipeline Değerlendirmesi ve İyileştirilmesi

## Giriş

Son zamanlarda yapılan araştırmalar, QA (Soru-Cevap) sistemlerinin geliştirilmesinde okuma anlama modellerinin iyileştirilmesine odaklanmıştır. Ancak pratikte, eğer retriever (bulucu) ilgili belgeleri ilk etapta bulamazsa, okuyucunun (reader) ne kadar iyi olduğu önemli değildir. Bu nedenle, retriever'ın performansı tüm QA sisteminin performansı için üst sınır oluşturur.

## Retriever Değerlendirmesi

Retriever'ı değerlendirmek için kullanılan yaygın bir metrik "recall" (geri çağırma) değeridir. Recall, bulunan belgeler arasında ilgili belgelerin oranını ölçer. Haystack kütüphanesinde retriever'ı değerlendirmek için iki yöntem vardır:

1. Retriever'ın dahili `eval()` metodu kullanılır.
2. Özel bir Pipeline oluşturularak `EvalRetriever` sınıfı ile retriever birleştirilir.

Bu örnekte, ikinci yaklaşım kullanılarak `EvalRetrieverPipeline` sınıfı oluşturulmuştur.

### Kod Açıklaması

```python
class EvalRetrieverPipeline:
    def __init__(self, retriever):
        self.retriever = retriever
        self.eval_retriever = EvalDocuments()
        pipe = Pipeline()
        pipe.add_node(component=self.retriever, name="ESRetriever", inputs=["Query"])
        pipe.add_node(component=self.eval_retriever, name="EvalRetriever", inputs=["ESRetriever"])
        self.pipeline = pipe
```

*   `EvalRetrieverPipeline` sınıfı, retriever ve `EvalDocuments` nesnelerini birleştirerek bir Pipeline oluşturur.
*   `add_node` metodu ile Pipeline'a düğümler eklenir.

## Retriever Değerlendirme Metrikleri

Recall dışında, retriever performansını değerlendirmek için kullanılan bir diğer metrik "mean average precision" (mAP) değeridir. mAP, doğru cevapların belge sıralamasında daha üst sıralarda yer almasını ödüllendirir.

### Kod Açıklaması

```python
def evaluate_retriever(retriever, topk_values=[1, 3, 5, 10, 20]):
    topk_results = {}
    for topk in topk_values:
        p = EvalRetrieverPipeline(retriever)
        run_pipeline(p, top_k_retriever=topk)
        topk_results[topk] = {"recall": p.eval_retriever.recall}
    return pd.DataFrame.from_dict(topk_results, orient="index")
```

*   `evaluate_retriever` fonksiyonu, retriever'ı farklı `top_k` değerleri için değerlendirir ve recall değerlerini hesaplar.

## Yoğun Vektör Gösterimleri ile Doküman Bulma

Sparse retriever'ların (örneğin BM25) sınırlamaları vardır; özellikle, kullanıcı sorgusu ile belge terimleri tam olarak eşleşmediğinde ilgili belgeleri bulmakta başarısız olabilirler. Yoğun vektör gösterimleri (dense embeddings) kullanarak dokümanları temsil etmek, bu sınırlamaları aşmak için umut verici bir alternatiftir.

### Kod Açıklaması

```python
dpr_retriever = DensePassageRetriever(
    document_store=document_store,
    query_embedding_model="facebook/dpr-question_encoder-single-nq-base",
    passage_embedding_model="facebook/dpr-ctx_encoder-single-nq-base",
    embed_title=False
)
```

*   `DensePassageRetriever` sınıfı, yoğun vektör gösterimleri kullanarak dokümanları temsil eder.

## Reader Değerlendirmesi

Reader'ı değerlendirmek için kullanılan metrikler "Exact Match" (EM) ve "F1 score" değerleridir. EM, tahmin edilen cevabın gerçek cevapla tam olarak eşleşip eşleşmediğini ölçer. F1 score ise, tahmin edilen cevabın gerçek cevaba ne kadar yakın olduğunu ölçer.

### Kod Açıklaması

```python
def evaluate_reader(reader):
    score_keys = ['top_1_em', 'top_1_f1']
    eval_reader = EvalAnswers(skip_incorrect_retrieval=False)
    pipe = Pipeline()
    pipe.add_node(component=reader, name="QAReader", inputs=["Query"])
    pipe.add_node(component=eval_reader, name="EvalReader", inputs=["QAReader"])
    for l in labels_agg:
        doc = document_store.query(l.question, filters={"question_id": [l.origin]})
        _ = pipe.run(query=l.question, documents=doc, labels=l)
    return {k: v for k, v in eval_reader.__dict__.items() if k in score_keys}
```

*   `evaluate_reader` fonksiyonu, reader'ı değerlendirir ve EM ve F1 score değerlerini hesaplar.

## Alan Uyarlaması (Domain Adaptation)

SQuAD gibi büyük veri kümelerinde eğitilen modeller, diğer alanlarda (örneğin SubjQA) kötü performans gösterebilir. Bu sorunu aşmak için, modeli hedef alanın veri kümesi üzerinde fine-tune etmek gerekir.

### Kod Açıklaması

```python
reader.train(data_dir=".", use_gpu=True, n_epochs=1, batch_size=16, train_filename=train_filename, dev_filename=dev_filename)
```

*   `train` metodu, reader'ı belirtilen veri kümesi üzerinde fine-tune eder.

## Genel Performans Değerlendirmesi

QA pipeline'ın genel performansını değerlendirmek için, retriever ve reader'ın performansını birlikte değerlendirmek gerekir.

### Kod Açıklaması

```python
pipe = EvalRetrieverPipeline(es_retriever)
eval_reader = EvalAnswers()
pipe.pipeline.add_node(component=reader, name="QAReader", inputs=["EvalRetriever"])
pipe.pipeline.add_node(component=eval_reader, name="EvalReader", inputs=["QAReader"])
run_pipeline(pipe)
```

*   `EvalRetrieverPipeline` sınıfı, retriever ve reader'ı birleştirerek bir Pipeline oluşturur.

---

## Going Beyond Extractive QA

# Özetleyici Soru-Cevap (Abstractive QA) ve Retrieval-Augmented Generation (RAG)

Bu bölümde, bir belge içindeki metin parçalarını çıkarmak yerine, önceden eğitilmiş bir dil modeli kullanarak cevaplar oluşturma yaklaşımı ele alınmaktadır. Bu yaklaşım, özetleyici veya üretken soru-cevap (abstractive veya generative QA) olarak bilinir ve birden fazla pasajdaki kanıtları sentezleyerek daha iyi ifade edilmiş cevaplar üretebilir.

## Retrieval-Augmented Generation (RAG)

RAG, klasik retriever-okuyucu mimarisini genişleterek okuyucuyu bir üreticiyle değiştirir ve DPR (Dense Passage Retriever)'ı retriever olarak kullanır. Üretici, T5 veya BART gibi önceden eğitilmiş bir dizi-dizi (sequence-to-sequence) transformatördür ve DPR'den gelen belgelerin latent vektörlerini alır, ardından sorgu ve bu belgeler temelinde bir cevap üretir.

### RAG'ın Özellikleri

*   RAG, hem sorgu kodlayıcısı hem de üreticiyi uçtan uca (end-to-end) eğitir, ancak bağlam kodlayıcısı dondurulur (frozen).
*   İki tür RAG modeli vardır:
    *   RAG-Sequence: Tam cevabı oluşturmak için aynı alınan belgeyi kullanır.
    *   RAG-Token: Cevapdaki her tokeni oluşturmak için farklı bir belge kullanabilir.

### RAG'ı Uygulama

RAG'ı uygulamak için Haystack kütüphanesini kullanacağız.

```python
from haystack.generator.transformers import RAGenerator

generator = RAGenerator(
    model_name_or_path="facebook/rag-token-nq",
    embed_title=False,
    num_beams=5
)
```

*   `model_name_or_path`: Kullanılacak RAG modelinin adı veya yolu.
*   `embed_title`: Belge başlıklarını gömme (embedding) yapılıp yapılmayacağı.
*   `num_beams`: Işın arama (beam search) için kullanılacak ışın sayısı.

Ardından, retriever ve üreticiyi Haystack'in `GenerativeQAPipeline` sınıfını kullanarak birleştiriyoruz:

```python
from haystack.pipeline import GenerativeQAPipeline

pipe = GenerativeQAPipeline(generator=generator, retriever=dpr_retriever)
```

### Sorgulama

Sorgulama yapmak için basit bir fonksiyon yazıyoruz:

```python
def generate_answers(query, top_k_generator=3):
    preds = pipe.run(
        query=query,
        top_k_generator=top_k_generator,
        top_k_retriever=5,
        filters={"item_id": ["B0074BW614"]}
    )
    print(f"Question: {preds['query']}\n")
    for idx in range(top_k_generator):
        print(f"Answer {idx+1}: {preds['answers'][idx]['answer']}")
```

Bu fonksiyon, verilen sorguyu çalıştırır ve en iyi cevapları yazdırır.

### Örnek Kullanım

```python
generate_answers("Is it good for reading?")
```

Çıktı:

```
Question: Is it good for reading?

Answer 1:  the screen is absolutely beautiful
Answer 2:  the Screen is absolutely beautiful
Answer 3:  Kindle fire
```

```python
generate_answers("What is the main drawback?")
```

Çıktı:

```
Question: What is the main drawback?

Answer 1:  the price
Answer 2:  no flash support
Answer 3:  the cost
```

Daha iyi sonuçlar elde etmek için RAG'ı SubjQA üzerinde uçtan uca ince ayar yapabilirsiniz (fine-tune).

---

## Conclusion

# Soru-Cevap Sistemleri (Question Answering Systems) ve Uygulama Alanları

Bu bölümde, Soru-Cevap (QA) sistemlerine ilişkin iki yaklaşım (çıkarımsal (extractive) ve üretken (generative)) ve iki farklı erişim algoritması (BM25 ve DPR) incelenmiştir. Ayrıca, alan adaptasyonunun (domain adaptation) QA sistemlerinin performansını önemli ölçüde artırmak için basit bir teknik olabileceği görülmüştür. QA sistemlerinin değerlendirilmesinde kullanılan en yaygın ölçütler de ele alınmıştır.

## QA Sistemlerine Yaklaşımlar
QA sistemlerine iki temel yaklaşım vardır:
1. **Çıkarımsal (Extractive) QA**: Bu yaklaşımda, sistem belirli bir metinden cevabı doğrudan çıkarır.
2. **Üretken (Generative) QA**: Bu yaklaşımda, sistem cevabı sıfırdan üretir.

## Erişim Algoritmaları
1. **BM25**: Belirli bir sorgu için belgeleri sıralamak üzere tasarlanmış bir algoritmadır. 
2. **DPR (Dense Passage Retriever)**: Daha gelişmiş bir erişim algoritmasıdır ve metinleri daha etkili bir şekilde sıralayabilir.

## Kod Örnekleri ve Açıklamaları
Bu bölümde spesifik kod örnekleri verilmemiştir, ancak QA sistemlerinin geliştirilmesinde kullanılan bazı teknikler ve kütüphanelerden bahsedilmiştir. Örneğin, `transformers` kütüphanesi gibi.

## Uygulama Alanları ve Gelecek Perspektifleri
1. **Multimodal QA**: Metin, tablo ve resim gibi farklı modları içeren QA sistemleridir.
2. **Bilgi Grafiği Üzerinde QA**: Düğümlerin gerçek dünya varlıklarına karşılık geldiği ve kenarların bu varlıklar arasındaki ilişkileri tanımladığı bir grafik üzerinde QA yapmaktır.
3. **Otomatik Soru Üretimi**: Denetimsiz veya zayıf denetimli eğitim için etiketlenmemiş verileri kullanma yöntemidir.

## Hızlandırma Yöntemleri
QA modellerinin gerçek dünya kullanım durumları için başarılı bir şekilde kullanılabilmesi için hızlı bir erişim hattı uygulanması gerektiği vurgulanmıştır. Gelecek bölümde model tahminlerini daha da hızlandırmak için bazı yöntemler ele alınacaktır.

### Önemli Noktalar:
- QA sistemlerine çıkarımsal ve üretken olmak üzere iki yaklaşım vardır.
- BM25 ve DPR gibi erişim algoritmaları QA sistemlerinin performansını etkiler.
- Alan adaptasyonu QA sistemlerinin performansını artırabilir.
- Multimodal QA, bilgi grafiği üzerinde QA ve otomatik soru üretimi gelecek vaat eden araştırma alanlarıdır.

### Teknik Terimler:
- **Domain Adaptation (Alan Adaptasyonu)**: Bir modelin bir alandan diğerine aktarılması ve yeni alanda daha iyi performans göstermesi için yapılan işlemlerdir.
- **Extractive QA (Çıkarımsal Soru-Cevap)**: Cevabın doğrudan metinden çıkarılmasıdır.
- **Generative QA (Üretken Soru-Cevap)**: Cevabın sıfırdan üretilmesidir.
- **BM25**: Bir erişim algoritmasıdır.
- **DPR (Dense Passage Retriever)**: Gelişmiş bir erişim algoritmasıdır.
- **Multimodal QA**: Farklı veri türlerini içeren QA sistemleridir.

### Kodlar ve Açıklamaları:
Bu metinde spesifik kodlar verilmemiştir. Ancak, QA sistemlerinin geliştirilmesinde `transformers` gibi kütüphaneler ve DPR, BM25 gibi algoritmalar kullanılır. Örneğin, bir DPR modeli aşağıdaki gibi kullanılabilir:
```python
from transformers import DPRQuestionEncoder, DPRContextEncoder

# Soru kodlayıcı ve içerik kodlayıcı modellerini yükle
question_encoder = DPRQuestionEncoder.from_pretrained("facebook/dpr-question_encoder-multiset-base")
context_encoder = DPRContextEncoder.from_pretrained("facebook/dpr-ctx_encoder-multiset-base")

# Soru ve içerik vektörlerini oluştur
question_embedding = question_encoder(**{"input_ids": question_input_ids, "attention_mask": question_attention_mask})[0]
context_embedding = context_encoder(**{"input_ids": context_input_ids, "attention_mask": context_attention_mask})[0]

# Benzerlik skorunu hesapla
similarity_score = torch.matmul(question_embedding, context_embedding.T)
```
Bu kod, bir soru ve bir içerik arasındaki benzerliği hesaplamak için DPR modellerini kullanır. İlk olarak, soru ve içerik kodlayıcı modelleri yüklenir. Daha sonra, soru ve içerik metinleri bu modeller aracılığıyla vektörlere dönüştürülür. Son olarak, bu vektörler arasındaki benzerlik skoru hesaplanır.

---

