## Scaling Transformers

# Ölçeklenebilirlik (Scaling) ve Transformer Mimarisi

Transformer mimarisi, doğal dil işleme (NLP) görevlerinde büyük başarılar elde etmiştir. Ancak, bu modellerin boyutu ve hesaplama gereksinimleri arttıkça, çeşitli zorluklar ortaya çıkmaktadır.

## Ölçeklenebilirlik Yasaları (Scaling Laws)

Ölçeklenebilirlik yasaları, dil modellerinin performansını, model boyutu (N), hesaplama bütçesi (C) ve veri seti boyutu (D) ile ilişkilendirir. Bu yasalar, model performansının bu faktörlerle nasıl değiştiğini gösterir.

L(X) ∼ 1 / X^α

Burada X, N, C veya D olabilir ve α, ölçeklendirme üssü (scaling exponent) olarak adlandırılır.

Kod örneği:
```python
import numpy as np

# Model boyutu, hesaplama bütçesi ve veri seti boyutu
N = np.array([100, 200, 300, 400, 500])
C = np.array([10, 20, 30, 40, 50])
D = np.array([1000, 2000, 3000, 4000, 5000])

# Ölçeklendirme üssü (α)
alpha_N = 0.05
alpha_C = 0.07
alpha_D = 0.09

# Model performansı (L)
L_N = 1 / (N ** alpha_N)
L_C = 1 / (C ** alpha_C)
L_D = 1 / (D ** alpha_D)

print("Model Performansı (L_N):", L_N)
print("Model Performansı (L_C):", L_C)
print("Model Performansı (L_D):", L_D)
```

Kod açıklaması:

*   Model boyutu (N), hesaplama bütçesi (C) ve veri seti boyutu (D) için numpy dizileri oluşturulur.
*   Ölçeklendirme üssü (α) değerleri belirlenir.
*   Model performansı (L), ölçeklendirme yasalarına göre hesaplanır.
*   Sonuçlar yazdırılır.

## Ölçeklenebilirlik Zorlukları

Transformer modellerinin ölçeklendirilmesi çeşitli zorluklar içerir:

*   Altyapı sağlama ve yönetme
*   Büyük ölçekli deneyler için gereken kaynaklar
*   Yüksek kaliteli veri setleri oluşturma
*   Model değerlendirme ve bias kontrolü
*   Model sunumu ve deployment

## Etkin Self-Attention Mekanizmaları

Self-attention mekanizması, Transformer mimarisinin temel bileşenidir. Ancak, bu mekanizma, uzun diziler için hesaplama açısından pahalı olabilir.

Etkin self-attention mekanizmaları geliştirmek için çeşitli yöntemler önerilmiştir:

*   Seyreklik (sparsity) tabanlı yöntemler
*   Çekirdek (kernel) tabanlı yöntemler

Seyreklik tabanlı yöntemler, dikkat matrisinde seyrek yapılar oluşturarak hesaplama karmaşıklığını azaltır.

Kod örneği:
```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class SparseAttention(nn.Module):
    def __init__(self, num_heads, hidden_size, sparsity_pattern):
        super(SparseAttention, self).__init__()
        self.num_heads = num_heads
        self.hidden_size = hidden_size
        self.sparsity_pattern = sparsity_pattern

    def forward(self, query, key, value):
        # Seyrek dikkat matrisi oluştur
        attention_scores = torch.matmul(query, key.T)
        attention_scores = attention_scores.masked_fill(self.sparsity_pattern == 0, -float('inf'))
        attention_weights = F.softmax(attention_scores, dim=-1)

        # Değerleri ağırlıklandır
        output = torch.matmul(attention_weights, value)
        return output

# Seyrek dikkat matrisi oluştur
sparsity_pattern = torch.tensor([[1, 0, 1], [0, 1, 0], [1, 0, 1]])

# Model oluştur
model = SparseAttention(num_heads=8, hidden_size=512, sparsity_pattern=sparsity_pattern)

# Girdi oluştur
query = torch.randn(1, 10, 512)
key = torch.randn(1, 10, 512)
value = torch.randn(1, 10, 512)

# Çıktı hesapla
output = model(query, key, value)
print("Çıktı:", output.shape)
```

Kod açıklaması:

*   Seyrek dikkat matrisi oluşturmak için bir maske kullanılır.
*   Dikkat skorları hesaplanır ve seyrek dikkat matrisine göre ağırlıklandırılır.
*   Değerler ağırlıklandırılarak çıktı hesaplanır.

## Doğrusal Self-Attention Mekanizmaları

Doğrusal self-attention mekanizmaları, dikkat skorlarını hesaplamak için çekirdek fonksiyonları kullanır.

Kod örneği:
```python
import torch
import torch.nn as nn

class LinearAttention(nn.Module):
    def __init__(self, num_heads, hidden_size):
        super(LinearAttention, self).__init__()
        self.num_heads = num_heads
        self.hidden_size = hidden_size

    def forward(self, query, key, value):
        # Çekirdek fonksiyonu uygula
        query = torch.relu(query)
        key = torch.relu(key)

        # Dikkat skorlarını hesapla
        attention_scores = torch.matmul(query, key.T)

        # Değerleri ağırlıklandır
        output = torch.matmul(attention_scores, value)
        return output

# Model oluştur
model = LinearAttention(num_heads=8, hidden_size=512)

# Girdi oluştur
query = torch.randn(1, 10, 512)
key = torch.randn(1, 10, 512)
value = torch.randn(1, 10, 512)

# Çıktı hesapla
output = model(query, key, value)
print("Çıktı:", output.shape)
```

Kod açıklaması:

*   Çekirdek fonksiyonu (örneğin, ReLU) uygulanarak dikkat skorları hesaplanır.
*   Değerler ağırlıklandırılarak çıktı hesaplanır.

Bu yöntemler, Transformer modellerinin daha verimli ve ölçeklenebilir hale getirilmesine yardımcı olur.

---

## Going Beyond Text

# Metin Sınırlamalarını Aşmak (Going Beyond Text)

## Giriş

Dil modellerinin eğitiminde metin kullanımı, transfer öğrenimi ile birlikte transformer dil modellerinin başarısının arkasındaki itici güç olmuştur. Ancak, bu yaklaşımın bazı sınırlamaları vardır. Bu sınırlamaları aşmak için, son zamanlarda transformer'ların yeni modalitelere ve hatta çoklu modal modellere uygulanmasında büyük ilerlemeler kaydedilmiştir.

## Metin Sınırlamaları

- Metindeki olayların frekansları gerçek frekanslarını temsil etmeyebilir.
- İnternetten alınan metinlerle eğitilen bir model, dünyanın çarpık bir görüntüsüne sahip olabilir.
- Sağduyu (Common Sense), insan muhakemesinin temel bir niteliğidir, ancak nadiren yazıya dökülür.
- Olasılıksal dil modelleri, gerçekleri güvenilir bir şekilde saklayamaz ve gerçek dışı metinler üretebilir.
- Dil modellerinin diğer modalitelere (örneğin, ses veya görsel sinyaller veya tablo verileri) bağlanmasının bir yolu yoktur.

## Yeni Modalitelere Geçiş

### Görüntü İşleme (Vision)

Görüntü işleme alanında, evrişimli sinir ağları (CNN'ler) uzun süredir hakimdir. Ancak, son zamanlarda transformer'lar bu alanda da uygulanmaya başlanmıştır.

#### iGPT (Image GPT)

iGPT, GPT ailesinin başarısından esinlenerek, aynı yöntemleri görüntülere uygular. Görüntüleri piksellerin dizisi olarak görür ve GPT mimarisini ve otoregresif ön eğitim hedefini kullanarak bir sonraki piksel değerlerini tahmin eder.

#### Vision Transformer (ViT)

ViT, BERT benzeri bir yaklaşımı görüntülere uygular. Görüntüyü daha küçük parçalara ayırır ve her bir parçayı doğrusal bir izdüşümle gömülü hale getirir. Bu gömülü parçalar, konum gömülmeleri ile birleştirilir ve sıradan bir transformer kodlayıcıdan geçirilir.

## Kod Örnekleri

### ViT Modelini Kullanma

```python
from PIL import Image
import matplotlib.pyplot as plt

image = Image.open("images/doge.jpg")
plt.imshow(image)
plt.axis("off")
plt.show()

import pandas as pd
from transformers import pipeline

image_classifier = pipeline("image-classification")
preds = image_classifier(image)
preds_df = pd.DataFrame(preds)
preds_df
```

**Kod Açıklaması:**

1. `Image.open("images/doge.jpg")`: "doge.jpg" adlı görüntüyü açar.
2. `plt.imshow(image)`: Görüntüyü gösterir.
3. `pipeline("image-classification")`: Görüntü sınıflandırma işlem hattını yükler.
4. `image_classifier(image)`: Görüntüyü sınıflandırır ve tahminleri döndürür.
5. `pd.DataFrame(preds)`: Tahminleri bir Pandas DataFrame'e dönüştürür.

### TAPAS (Table Parser)

TAPAS, tablo verilerini işlemek için transformer mimarisini uygular. Tablo bilgisini sorgu ile birleştirir.

#### Kod Örneği

```python
book_data = [
    {"chapter": 0, "name": "Introduction", "start_page": 1, "end_page": 11},
    {"chapter": 1, "name": "Text classification", "start_page": 12, "end_page": 48},
    # ...
]

table = pd.DataFrame(book_data)
table['number_of_pages'] = table['end_page'] - table['start_page']
table = table.astype(str)

table_qa = pipeline("table-question-answering")
queries = ["What's the topic in chapter 4?", "What is the total number of pages?"]
preds = table_qa(table, queries)

for query, pred in zip(queries, preds):
    print(query)
    if pred["aggregator"] == "NONE":
        print("Predicted answer: " + pred["answer"])
    else:
        print("Predicted answer: " + pred["answer"])
    print('=' * 50)
```

**Kod Açıklaması:**

1. `pd.DataFrame(book_data)`: `book_data` listesinden bir Pandas DataFrame oluşturur.
2. `table['number_of_pages'] = table['end_page'] - table['start_page']`: Her bir bölümün sayfa sayısını hesaplar.
3. `pipeline("table-question-answering")`: Tablo-soru-cevap işlem hattını yükler.
4. `table_qa(table, queries)`: Tablodan sorgulara cevap verir.
5. `for` döngüsü: Sorguları ve tahminleri yazdırır.

---

## Multimodal Transformers

# Multimodal Transformers (Çok Modlu Dönüştürücüler)

Bu bölümde, transformer modellerinin birden fazla mod (mesela metin ve ses veya metin ve görüntü) ile nasıl çalışabileceğini inceleyeceğiz.

## Otomatik Konuşma Tanıma (Automatic Speech Recognition - ASR)

Otomatik konuşma tanıma, konuşulan kelimeleri metne çevirme görevidir. Bu, Siri gibi sesli teknolojilerin "Bugün hava nasıl?" gibi soruları cevaplamasını sağlar. Wav2vec 2.0 model ailesi, ASR'de son gelişmelerden biridir. Bu modeller, bir transformer katmanı ve bir CNN (Convolutional Neural Network) kullanır.

### Wav2vec 2.0 Modelini Kullanma

Wav2vec 2.0 modelleri Transformers kütüphanesinde entegre edilmiştir. Aşağıdaki kod, önceden eğitilmiş bir modeli yükler ve bir ses dosyasını metne çevirir:
```python
asr = pipeline("automatic-speech-recognition")
from datasets import load_dataset
ds = load_dataset("superb", "asr", split="validation[:1]")
print(ds[0])
```
Çıktı:
```json
{'chapter_id': 128104, 'speaker_id': 1272, 'file': '~/.cache/huggingface/datasets/downloads/extracted/e4e70a454363bec1c1a8ce336139866a39442114d86a4336014acd4b1ed55e55/LibriSpeech/dev-clean/1272/128104/1272-128104-0000.flac', 'id': '1272-128104-0000', 'text': 'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL'}
```
Ses dosyasını bir float dizisine çevirmek için SoundFile kütüphanesini kullanıyoruz:
```python
import soundfile as sf
def map_to_array(batch):
    speech, _ = sf.read(batch["file"])
    batch["speech"] = speech
    return batch
ds = ds.map(map_to_array)
```
Ardından, ses dosyasını modele geçiriyoruz:
```python
pred = asr(ds[0]["speech"])
print(pred)
```
Çıktı:
```json
{'text': 'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL'}
```
Bu, doğru bir transkripsiyon gibi görünüyor.

### Kod Açıklamaları

* `asr = pipeline("automatic-speech-recognition")`: Önceden eğitilmiş bir ASR modelini yükler.
* `ds = load_dataset("superb", "asr", split="validation[:1]")`: SUPERB veri kümesinin ASR alt kümesini yükler.
* `print(ds[0])`: Veri kümesindeki ilk örneği yazdırır.
* `map_to_array` fonksiyonu: Ses dosyasını bir float dizisine çevirir.
* `ds = ds.map(map_to_array)`: Veri kümesindeki her örneği `map_to_array` fonksiyonu ile işler.
* `pred = asr(ds[0]["speech"])`: Ses dosyasını modele geçirir ve transkripsiyonu alır.

## Görüntü ve Metin Modelleri

Görüntü ve metin, birbiriyle ilişkili iki moddur. Bu bölümde, görüntü ve metin modellerini inceleyeceğiz.

### CLIP Modeli

CLIP modeli, görüntü ve metin arasındaki ilişkiyi öğrenen bir modeldir. Aşağıdaki kod, CLIP modelini yükler ve bir görüntü ile metin arasındaki benzerliği hesaplar:
```python
from transformers import CLIPProcessor, CLIPModel
clip_ckpt = "openai/clip-vit-base-patch32"
model = CLIPModel.from_pretrained(clip_ckpt)
processor = CLIPProcessor.from_pretrained(clip_ckpt)
image = Image.open("images/optimusprime.jpg")
texts = ["a photo of a transformer", "a photo of a robot", "a photo of agi"]
inputs = processor(text=texts, images=image, return_tensors="pt", padding=True)
with torch.no_grad():
    outputs = model(**inputs)
    logits_per_image = outputs.logits_per_image
    probs = logits_per_image.softmax(dim=1)
    print(probs)
```
Çıktı:
```python
tensor([[0.9557, 0.0413, 0.0031]])
```
Bu, görüntü ile metin arasındaki benzerliği gösterir.

### Kod Açıklamaları

* `model = CLIPModel.from_pretrained(clip_ckpt)`: CLIP modelini yükler.
* `processor = CLIPProcessor.from_pretrained(clip_ckpt)`: CLIP işlemcisini yükler.
* `image = Image.open("images/optimusprime.jpg")`: Görüntüyü yükler.
* `texts = ["a photo of a transformer", "a photo of a robot", "a photo of agi"]`: Metinleri tanımlar.
* `inputs = processor(text=texts, images=image, return_tensors="pt", padding=True)`: Görüntü ve metinleri modele uygun hale getirir.
* `outputs = model(**inputs)`: Modeli çalıştırır.
* `logits_per_image = outputs.logits_per_image`: Görüntü ile metin arasındaki benzerliği hesaplar.
* `probs = logits_per_image.softmax(dim=1)`: Benzerlikleri softmax fonksiyonu ile işler.

---

## Where to from Here?

# Nereye Gidilir? (Where to from Here?)

Bu bölümde, transformer (dönüştürücü) modellerinin sınırlarının zorlandığı ve yeni alanlara yayıldığı görülmektedir. Kitap boyunca, transformer'ların çeşitli görevleri yerine getirebileceği ve en son teknoloji sonuçlar elde edebileceği incelenmiştir.

## Öğrenilenleri Pekiştirme (Reinforcing Concepts)

Öğrenilen kavram ve becerileri pekiştirmek için birkaç öneri:
- Hugging Face tarafından düzenlenen kısa süreli sprintlere (sprints) katılın. Bu etkinlikler, toplulukla tanışmak ve açık kaynaklı yazılım geliştirme deneyimi kazanmak için harika bir yoldur.
- Kendi projelerinizi geliştirerek makine öğrenimi konusundaki bilgilerinizi test edin. Bir transformer makalesini yeniden uygulayabilir veya transformer'ları yeni bir alana uygulayabilirsiniz.

## Topluluğa Katılma (Joining the Community)

- Yeni yayımlanan bir mimariyi (architecture) Transformers kütüphanesine katkıda bulunmak, kütüphanenin işleyişini daha iyi anlamak için harika bir yoldur. 
- Transformers dokümantasyonunda (⁠Transformers documentation) detaylı bir kılavuz bulunmaktadır.

## Başkalarına Öğretme (Teaching Others)

- Öğrendiklerinizi başkalarına öğretmek, kendi bilgilerinizi test etmenin güçlü bir yoludur. Teknik blog yazmak için fastpages gibi araçlar kullanılabilir. Jupyter notebook'ları kullanarak kolayca içerik oluşturabilirsiniz.

### Kullanılan Kodlar ve Açıklamaları

Paragrafta doğrudan kod geçmemektedir, ancak transformer'larla ilgili projeler geliştirirken kullanılabilecek bazı kütüphaneler ve araçlar belirtilmiştir:
- **Datasets**: Hugging Face tarafından sunulan bir kütüphane. Büyük veri setlerini kolayca işleyebilir ve kullanabilirsiniz.
- **JAX/Flax**: Google tarafından geliştirilen JAX kütüphanesine dayanan bir derin öğrenme kütüphanesi. Yüksek performanslı makine öğrenimi modelleri geliştirmek için kullanılır.
- **Transformers**: Hugging Face tarafından geliştirilen ve çeşitli transformer tabanlı modelleri içeren bir kütüphane. Metin işleme, görüntü işleme gibi görevler için kullanılabilir.
- **fastpages**: Teknik bloglar oluşturmak için kullanılan bir araç. Jupyter notebook'ları kullanarak kolayca içerik oluşturmanıza olanak tanır.

Bu araçlar ve kütüphaneler, makine öğrenimi ve transformer'larla ilgili projeler geliştirirken kullanılabilir. Örneğin, bir transformer modelini fine-tuning (ince ayar) yapmak için Transformers kütüphanesini kullanabilirsiniz.

```python
# Örnek kod: Transformers kütüphanesini kullanarak bir modelin ince ayarı
from transformers import AutoModelForSequenceClassification, AutoTokenizer
import torch

# Model ve tokenizer'ı yükle
model_name = "bert-base-uncased"
model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Örnek veri
text = "Bu bir örnek cümledir."

# Veriyi tokenize et
inputs = tokenizer(text, return_tensors="pt")

# Modeli kullanarak tahmin yap
outputs = model(**inputs)

# Tahmin sonuçlarını işle
logits = outputs.logits
predicted_class = torch.argmax(logits)

print(f"Tahmin edilen sınıf: {predicted_class}")
```

Bu kod, `bert-base-uncased` modelini kullanarak bir metin sınıflandırma görevi için ince ayar yapmaktadır. `AutoModelForSequenceClassification` ve `AutoTokenizer` sınıfları, sırasıyla model ve tokenizer'ı yüklemek için kullanılır. `from_pretrained` metodu, önceden eğitilmiş modeli veya tokenizer'ı yükler. `tokenizer` metodu, metni modele uygun bir formata dönüştürür. Model daha sonra bu girdileri işleyerek bir tahminde bulunur.

---

