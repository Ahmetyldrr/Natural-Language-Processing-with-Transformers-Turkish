## The CNN/DailyMail Dataset

# CNN/DailyMail Veri Kümesi (Dataset)

CNN/DailyMail veri kümesi, yaklaşık 300.000 haber makalesi ve bunlara karşılık gelen özetlerden oluşur. Bu özetler, CNN ve DailyMail'in makalelerine eklediği madde işaretlerinden (bullet points) oluşur. Veri kümesinin önemli bir yönü, özetlerin çıkarımcı (abstractive) olmasıdır, yani basit alıntılar yerine yeni cümlelerden oluşurlar.

## Veri Kümesinin Özellikleri

Veri kümesi üç sütundan oluşur:
- `article`: Haber makalelerini içerir.
- `highlights`: Özetleri içerir.
- `id`: Her makaleyi benzersiz şekilde tanımlar.

## Veri Kümesine Erişim

Veri kümesine Hub üzerinden erişilebilir. Versiyon 3.0.0'ı kullanacağız, bu özetleme için hazırlanmış anonimleştirilmemiş bir versiyondur. Versiyonları, Bölüm 4'te gördüğümüz gibi, bir `version` anahtar kelimesi ile seçebiliriz.

```python
from datasets import load_dataset
dataset = load_dataset("cnn_dailymail", version="3.0.0")
print(f"Features: {dataset['train'].column_names}")
```

Kod Açıklaması:
- `from datasets import load_dataset`: `datasets` kütüphanesinden `load_dataset` fonksiyonunu içe aktarır. Bu fonksiyon, veri kümelerini yüklemek için kullanılır.
- `dataset = load_dataset("cnn_dailymail", version="3.0.0")`: CNN/DailyMail veri kümesinin 3.0.0 versiyonunu yükler.
- `print(f"Features: {dataset['train'].column_names}")`: Yüklenen veri kümesinin `train` bölümündeki sütun isimlerini yazdırır.

Çıktı:
```
Features: ['article', 'highlights', 'id']
```

## Örnek Makale ve Özeti

```python
sample = dataset["train"][1]
print(f"""Article (excerpt of 500 characters, total length: {len(sample["article"])}):""")
print(sample["article"][:500])
print(f'\nSummary (length: {len(sample["highlights"])}):')
print(sample["highlights"])
```

Kod Açıklaması:
- `sample = dataset["train"][1]`: `train` bölümünden ikinci örneği (`index=1`) seçer.
- `print(sample["article"][:500])`: Seçilen makalenin ilk 500 karakterini yazdırır.
- `print(sample["highlights"])`: Seçilen örneğin özetini yazdırır.

Çıktı:
```
Article (excerpt of 500 characters, total length: 3192):
(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has n

Summary (length: 180):
Usain Bolt wins third gold of world championship. Anchors Jamaica to 4x100m relay victory. Eighth gold at the championships for Bolt. Jamaica double up in women's 4x100m relay.
```

## Uzun Makalelerin İşlenmesi

Makalenin uzunluğu özet uzunluğuna göre çok daha fazladır; bu örnekte fark 17 kattır. Uzun makaleler çoğu transformer modeli için bir zorluk teşkil eder çünkü bağlam boyutu (context size) genellikle 1000 token ya da birkaç paragraf metin ile sınırlıdır. Özetleme için standart ancak kaba bir yaklaşım, metinleri modelin bağlam boyutunun ötesinde kırpmaktır (truncate). Bu, özet için önemli bilgilerin metnin sonunda olabileceği anlamına gelir, ancak şimdilik model mimarilerinin bu sınırlamasıyla yaşamak zorundayız.

---

## Text Summarization Pipelines

# Metin Özetleme (Text Summarization) Boru Hatları

Metin özetleme, bir metnin ana noktalarını koruyarak daha kısa bir sürümünü oluşturma işlemidir. Bu işlem, büyük miktarda metin verisiyle çalışırken özellikle yararlıdır.

## Örnek Metin ve Özetleme İşlemi

Örnek bir metin alınarak çeşitli transformer modellerinin özetleme performansları karşılaştırılacaktır. Tüm modeller için girdi metni 2.000 karakter ile sınırlandırılmıştır: 
```python
sample_text = dataset["train"][1]["article"][:2000]
```
Bu kod, eğitim veri setindeki ikinci makalenin ilk 2.000 karakterini alır.

## Özet Cümlelerinin Ayrılması

Özet cümlelerini ayırmak için NLTK (Natural Language Toolkit) kütüphanesinin `sent_tokenize` fonksiyonu kullanılır:
```python
import nltk
from nltk.tokenize import sent_tokenize
nltk.download("punkt")
string = "The U.S. are a country. The U.N. is an organization."
sent_tokenize(string)
```
Bu kod, cümleleri noktalama işaretlerine göre ayırır ve kısaltmalar gibi özel durumları işler.

## Temel Özetleme Yöntemleri

1. **İlk Üç Cümle**: Makalelerin ilk üç cümlesini özet olarak almak yaygın bir temel yöntemdir:
   ```python
def three_sentence_summary(text):
    return "\n".join(sent_tokenize(text)[:3])
summaries["baseline"] = three_sentence_summary(sample_text)
```
   Bu fonksiyon, metni cümlelere ayırır ve ilk üç cümleyi birleştirerek özet oluşturur.

## Transformer Modelleriyle Özetleme

1. **GPT-2**: GPT-2 modeli, "TL;DR" ifadesini girdi metnine ekleyerek özetleme yapabilir:
   ```python
from transformers import pipeline, set_seed
set_seed(42)
pipe = pipeline("text-generation", model="gpt2-xl")
gpt2_query = sample_text + "\nTL;DR:\n"
pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)
summaries["gpt2"] = "\n".join(sent_tokenize(pipe_out[0]["generated_text"][len(gpt2_query):]))
```
   Bu kod, GPT-2 modelini kullanarak özetleme yapar. `max_length` parametresi, oluşturulan metnin maksimum uzunluğunu belirler.

2. **T5**: T5 modeli, çeşitli NLP görevlerini metin-metine dönüştürme görevi olarak formüle eder. Özetleme için "summarize: <ARTICLE>" formatını kullanır:
   ```python
pipe = pipeline("summarization", model="t5-large")
pipe_out = pipe(sample_text)
summaries["t5"] = "\n".join(sent_tokenize(pipe_out[0]["summary_text"]))
```
   T5 modeli, özetleme görevini doğrudan yerine getirebilir.

3. **BART**: BART modeli, bozulmuş girdileri yeniden yapılandırmayı öğrenir ve özetleme için kullanılabilir:
   ```python
pipe = pipeline("summarization", model="facebook/bart-large-cnn")
pipe_out = pipe(sample_text)
summaries["bart"] = "\n".join(sent_tokenize(pipe_out[0]["summary_text"]))
```
   BART, BERT ve GPT-2'nin ön eğitim şemalarını birleştirir.

4. **PEGASUS**: PEGASUS, çok cümleli metinlerde cümleleri maskelemeyi ve bu cümleleri tahmin etmeyi öğrenir:
   ```python
pipe = pipeline("summarization", model="google/pegasus-cnn_dailymail")
pipe_out = pipe(sample_text)
summaries["pegasus"] = pipe_out[0]["summary_text"].replace(".<n>", ".\n")
```
   PEGASUS, özetleme görevine özel olarak ön eğitilmiştir ve son teknoloji bir özetleme modeli olarak kabul edilir.

## Kodların Açıklaması

- `sample_text = dataset["train"][1]["article"][:2000]`: Eğitim veri setindeki ikinci makalenin ilk 2.000 karakterini alır.
- `sent_tokenize(string)`: Metni cümlelere ayırır.
- `three_sentence_summary(text)`: Metnin ilk üç cümlesini özet olarak döndürür.
- `pipeline("text-generation", model="gpt2-xl")`: GPT-2 modelini kullanarak metin oluşturma boru hattı oluşturur.
- `pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)`: GPT-2 modeli ile özetleme yapar.
- `pipeline("summarization", model="t5-large")`: T5 modelini kullanarak özetleme boru hattı oluşturur.
- `pipe(sample_text)`: T5, BART, ve PEGASUS modelleri ile özetleme yapar.

Bu modellerin her biri, farklı özetleme stratejileri kullanarak girdi metninin özetini oluşturur.

---

## Comparing Different Summaries

# Farklı Özetlerin Karşılaştırılması (Comparing Different Summaries)

Dört farklı model ile oluşturulan özetleri karşılaştıralım. Bir modelin veri seti üzerinde hiç eğitilmediğini (GPT-2), bir modelin bu görev için diğer görevlerle birlikte ince ayar yapıldığını (T5) ve iki modelin yalnızca bu görev için ince ayar yapıldığını (BART ve PEGASUS) unutmayın.

## Özetlerin Karşılaştırılması

Modellerin oluşturduğu özetlere bakalım:
```python
print("GROUND TRUTH")
print(dataset["train"][1]["highlights"])
print("")
for model_name in summaries:
    print(model_name.upper())
    print(summaries[model_name])
    print("")
```
Kod Açıklaması:
- `print("GROUND TRUTH")`: Gerçek özeti yazdırır.
- `print(dataset["train"][1]["highlights"])`: Veri setindeki gerçek özeti yazdırır.
- `for model_name in summaries`: Modellerin isimlerini döngüye sokar.
- `print(model_name.upper())`: Modelin ismini büyük harflerle yazdırır.
- `print(summaries[model_name])`: Modelin oluşturduğu özeti yazdırır.

## Özetler

### Gerçek Özet (Ground Truth)
Usain Bolt dünya şampiyonasında üçüncü altın madalya kazanır.
Jamaika'yı 4x100m bayrak yarışında zafere taşır.
Bolt şampiyonada sekizinci altın madalyasını kazanır.
Jamaika kadınlar 4x100m bayrak yarışında da şampiyon olur.

### Baseline
(CNN) -- Usain Bolt, Moskova'da dünya şampiyonasını erkekler 4x100m bayrak yarışında Jamaika'yı zafere taşıyarak üçüncü altın madalyasını kazanır.
Dünyanın en hızlı adamı, Amerikan rakibi Justin Gatlin'i geride bırakarak Jamaika takımı Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade ve Bolt'un 37.36 saniyede yarışı bitirmesini sağlar.

### GPT2
Nesta, dünyanın en hızlı adamı.
Gatlin, en başarılı Olimpiyat sporcusu.
Kemar, Jamaika'nın efsanesi.
Shelly-Ann, dünyanın en hızlı kadını.
Bolt, dünyanın en büyük sporcusu.
Sırıkla atlama takımı

### T5
usain bolt, erkekler 4x100m bayrak yarışında dünya şampiyonasında üçüncü altın madalyasını kazanır.
26 yaşındaki sporcu, Rusya'nın başkenti Moskova'da Jamaika'yı zafere taşır.
Şampiyonada sekizinci altın madalyasını kazanarak rekoru eşitler.

### BART
Usain Bolt, Moskova'da dünya şampiyonasında üçüncü altın madalyasını kazanır.
Bolt, Jamaika'yı erkekler 4x100m bayrak yarışında zafere taşır.
26 yaşındaki sporcu, dünya şampiyonasında sekizinci altın madalyasını kazanır.
Jamaika'nın kadın takımı da bayrak yarışında altın madalya kazanır.

### PEGASUS
Usain Bolt, dünya şampiyonasında üçüncü altın madalyasını kazanır.
Jamaika'yı erkekler 4x100m bayrak yarışında zafere taşır.
Bolt, şampiyonada sekizinci altın madalyasını kazanır.
Jamaika, kadınlar 4x100m bayrak yarışında da şampiyon olur.

## Karşılaştırma ve Değerlendirme

Model çıktılarına baktığımızda, GPT-2 tarafından oluşturulan özetin diğerlerinden oldukça farklı olduğunu görüyoruz. GPT-2, metni özetlemek yerine karakterleri özetlemektedir. GPT-2 modeli, doğru özetler oluşturmak için açıkça eğitilmediği için genellikle "halüsinasyon" yapar veya gerçek olmayan bilgiler üretir. Diğer üç modelin özetlerini gerçek özetle karşılaştırdığımızda, PEGASUS'un çıktısının en çok benzediğini görüyoruz.

## En İyi Modelin Seçilmesi

Dört model de niteliksel olarak makul sonuçlar vermektedir. Ancak, en iyi modeli belirlemek için sistematik bir yol izlemek gerekir. Bir metrik tanımlamak, bu metriği bazı benchmark veri setlerinde tüm modeller için ölçmek ve en iyi performansı gösteren modeli seçmek idealdir. Ancak, metin oluşturma görevi için bir metrik tanımlamak kolay değildir. İnsan tarafından yazılan "altın standart" özet için, eş anlamlılar, yeniden ifade etmeler veya gerçekleri biraz farklı bir şekilde formüle eden düzinelerce başka özet de kabul edilebilir olabilir.

## Metin Oluşturma Kalitesinin Ölçülmesi

Bir sonraki bölümde, oluşturulan metnin kalitesini ölçmek için geliştirilen bazı yaygın metrikleri inceleyeceğiz.

---

## Measuring the Quality of Generated Text

# Metin Oluşturma Kalitesinin Değerlendirilmesi (Evaluating Text Generation Quality)

İyi değerlendirme metrikleri (evaluation metrics) önemlidir, çünkü bunları sadece modelleri eğitirken değil, aynı zamanda üretim aşamasında da performanslarını ölçmek için kullanırız. Metin oluşturma görevlerinde (text generation tasks) performansı ölçmek, duygu analizi (sentiment analysis) veya adlandırılmış varlık tanıma (named entity recognition) gibi standart sınıflandırma görevlerine göre daha zordur.

## BLEU ve ROUGE Metrikleri

İki yaygın metin oluşturma metriği BLEU (Bilingual Evaluation Understudy) ve ROUGE (Recall-Oriented Understudy for Gisting Evaluation) skoru kullanır. BLEU, oluşturulan metin ile referans metin arasındaki benzerliği ölçer ve hassasiyet (precision) tabanlıdır. ROUGE ise, özetleme gibi görevlerde yüksek hatırlama (recall) oranını ödüllendirmek için geliştirilmiştir.

### BLEU Skoru

BLEU skoru, oluşturulan metindeki n-gram'ların (kelime dizileri) referans metinde de bulunma oranını ölçer. 
```python
from datasets import load_metric
bleu_metric = load_metric("sacrebleu")
```
BLEU skorunu hesaplamak için `sacrebleu` metriği kullanılır. Bu metrik, tokenizasyon adımını dahili olarak gerçekleştirir, böylece farklı tokenizasyon yöntemlerinden kaynaklanan değişkenlikleri önler.

```python
bleu_metric.add(prediction="the the the the the the", reference=["the cat is on the mat"])
results = bleu_metric.compute(smooth_method="floor", smooth_value=0)
```
Kod Açıklaması:
- `bleu_metric.add()`: Tek bir örnek ekler. `prediction` oluşturulan metni, `reference` ise referans metni temsil eder.
- `bleu_metric.compute()`: Eklenen tüm örnekler için BLEU skorunu hesaplar. `smooth_method` ve `smooth_value` parametreleri, sıfır sayımlı n-gram'lar için skorun daha düzgün hesaplanmasını sağlar.

### ROUGE Skoru

ROUGE skoru, oluşturulan metindeki n-gram'ların referans metinde de bulunma oranını ölçer, ancak BLEU'dan farklı olarak hatırlama (recall) oranını vurgular.
```python
rouge_metric = load_metric("rouge")
```
ROUGE metriği, oluşturulan metin ile referans metin arasındaki benzerliği ölçmek için kullanılır.

```python
rouge_metric.add(prediction=summaries[model_name], reference=reference)
score = rouge_metric.compute()
```
Kod Açıklaması:
- `rouge_metric.add()`: Tek bir örnek ekler. `prediction` oluşturulan özeti, `reference` ise referans özeti temsil eder.
- `rouge_metric.compute()`: Eklenen tüm örnekler için ROUGE skorunu hesaplar ve güven aralığı (confidence interval) dahil olmak üzere çeşitli metrikleri döndürür.

## Örnek Uygulama

BLEU ve ROUGE skorlarını kullanarak, farklı metin oluşturma modellerinin performansını karşılaştırabiliriz.
```python
reference = dataset["train"][1]["highlights"]
records = []
rouge_names = ["rouge1", "rouge2", "rougeL", "rougeLsum"]
for model_name in summaries:
    rouge_metric.add(prediction=summaries[model_name], reference=reference)
    score = rouge_metric.compute()
    rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)
    records.append(rouge_dict)
pd.DataFrame.from_records(records, index=summaries.keys())
```
Kod Açıklaması:
- `rouge_metric.add()` ve `rouge_metric.compute()`: Her model için ROUGE skorunu hesaplar.
- `pd.DataFrame.from_records()`: Tüm modellerin ROUGE skorlarını bir DataFrame'e dönüştürür.

Bu analiz, farklı metin oluşturma modellerinin kalitesini sistematik olarak değerlendirmek için kullanılabilir.

---

## Evaluating PEGASUS on the CNN/DailyMail Dataset

# CNN/DailyMail Veri Kümesinde PEGASUS'un Değerlendirilmesi (Evaluating PEGASUS on the CNN/DailyMail Dataset)

CNN/DailyMail veri kümesinde PEGASUS modelinin değerlendirilmesi için gerekli tüm parçaları bir araya getirdik: CNN/DailyMail'den test seti içeren bir veri kümesi, ROUGE metriği ve bir özetleme modeli (summarization model). Sadece parçaları bir araya getirmek kaldı.

## Temel Özetleme Modelinin Değerlendirilmesi (Evaluating the Three-Sentence Baseline)

İlk olarak, üç cümle temel özetleme modelinin (three-sentence baseline) performansını değerlendireceğiz:
```python
def evaluate_summaries_baseline(dataset, metric, column_text="article", column_summary="highlights"):
    summaries = [three_sentence_summary(text) for text in dataset[column_text]]
    metric.add_batch(predictions=summaries, references=dataset[column_summary])
    score = metric.compute()
    return score
```
Bu kod, veri kümesindeki her bir makale için üç cümle özetleme modelini kullanarak özetler oluşturur ve ROUGE metriği kullanarak bu özetlerin kalitesini değerlendirir.

* `dataset`: Değerlendirilecek veri kümesi
* `metric`: Kullanılacak metrik (ROUGE)
* `column_text`: Makalelerin bulunduğu sütun adı
* `column_summary`: Özetlerin bulunduğu sütun adı

## PEGASUS Modelinin Değerlendirilmesi (Evaluating the PEGASUS Model)

Şimdi, PEGASUS modelini değerlendirmek için aynı değerlendirme fonksiyonunu uygulayacağız:
```python
from tqdm import tqdm
import torch

device = "cuda" if torch.cuda.is_available() else "cpu"

def chunks(list_of_elements, batch_size):
    """Yield successive batch-sized chunks from list_of_elements."""
    for i in range(0, len(list_of_elements), batch_size):
        yield list_of_elements[i:i + batch_size]

def evaluate_summaries_pegasus(dataset, metric, model, tokenizer, batch_size=16, device=device, column_text="article", column_summary="highlights"):
    article_batches = list(chunks(dataset[column_text], batch_size))
    target_batches = list(chunks(dataset[column_summary], batch_size))

    for article_batch, target_batch in tqdm(zip(article_batches, target_batches), total=len(article_batches)):
        inputs = tokenizer(article_batch, max_length=1024, truncation=True, padding="max_length", return_tensors="pt")
        summaries = model.generate(input_ids=inputs["input_ids"].to(device), attention_mask=inputs["attention_mask"].to(device), length_penalty=0.8, num_beams=8, max_length=128)
        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, clean_up_tokenization_spaces=True) for s in summaries]
        decoded_summaries = [d.replace("<n>", " ") for d in decoded_summaries]
        metric.add_batch(predictions=decoded_summaries, references=target_batch)

    score = metric.compute()
    return score
```
Bu kod, PEGASUS modelini kullanarak özetler oluşturur ve ROUGE metriği kullanarak bu özetlerin kalitesini değerlendirir.

* `dataset`: Değerlendirilecek veri kümesi
* `metric`: Kullanılacak metrik (ROUGE)
* `model`: PEGASUS modeli
* `tokenizer`: PEGASUS tokenleştiricisi
* `batch_size`: Toplu işleme boyutu

## Modelin Yüklenmesi ve Değerlendirilmesi (Loading and Evaluating the Model)

PEGASUS modelini yükleyip değerlendirelim:
```python
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

model_ckpt = "google/pegasus-cnn_dailymail"
tokenizer = AutoTokenizer.from_pretrained(model_ckpt)
model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)

score = evaluate_summaries_pegasus(test_sampled, rouge_metric, model, tokenizer, batch_size=8)
rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)
pd.DataFrame(rouge_dict, index=["pegasus"])
```
Bu kod, PEGASUS modelini yükler ve `evaluate_summaries_pegasus` fonksiyonunu kullanarak değerlendirir.

 Sonuçlar, yayınlanan sonuçlara çok yakın. Burada dikkat edilmesi gereken bir nokta, kayıp (loss) ve token doğruluk (per-token accuracy) değerlerinin ROUGE skorlarından belli bir dereceye kadar bağımsız olmasıdır. Kayıp, decoding stratejisinden bağımsızken, ROUGE skoru decoding stratejisine bağlıdır. ROUGE ve BLEU skorları, insan değerlendirmesiyle daha iyi korelasyon gösterdiğinden, metin oluşturma modelleri geliştirirken decoding stratejisini dikkatlice seçmek önemlidir.

---

## Training a Summarization Model

# Özetleme Modeli Eğitimi (Training a Summarization Model)

Bu bölümde, metin özetleme ve değerlendirme konularını kullanarak özel bir metin özetleme modeli eğitmek için Samsung tarafından geliştirilen SAMSum veri kümesini kullanacağız.

## Veri Kümesini Yükleme (Loading the Dataset)

İlk olarak, SAMSum veri kümesini yükleyelim ve bir örnek görelim:
```python
dataset_samsum = load_dataset("samsum")
split_lengths = [len(dataset_samsum[split]) for split in dataset_samsum]
print(f"Split lengths: {split_lengths}")
print(f"Features: {dataset_samsum['train'].column_names}")
print("\nDialogue:")
print(dataset_samsum["test"][0]["dialogue"])
print("\nSummary:")
print(dataset_samsum["test"][0]["summary"])
```
Kod açıklamaları:

* `load_dataset("samsum")`: SAMSum veri kümesini yükler.
* `split_lengths`: Veri kümesinin eğitim, doğrulama ve test kümelerinin uzunluklarını hesaplar.
* `dataset_samsum['train'].column_names`: Veri kümesinin sütun adlarını yazdırır.
* `dataset_samsum["test"][0]["dialogue"]`: Test kümesindeki ilk diyalogu yazdırır.
* `dataset_samsum["test"][0]["summary"]`: Test kümesindeki ilk özeti yazdırır.

## Özetleme Modelini Değerlendirme (Evaluating the Summarization Model)

CNN/DailyMail veri kümesi üzerinde eğitilmiş bir modelin SAMSum veri kümesi üzerindeki performansını değerlendirelim:
```python
pipe_out = pipe(dataset_samsum["test"][0]["dialogue"])
print("Summary:")
print(pipe_out[0]["summary_text"].replace(".<n>", ".\n"))
```
Kod açıklamaları:

* `pipe(dataset_samsum["test"][0]["dialogue"])`: Diyalogu özetler.
* `pipe_out[0]["summary_text"]`: Özeti yazdırır.

## ROUGE Değerlendirmesi (ROUGE Evaluation)

Test kümesi üzerinde ROUGE değerlendirmesi yapalım:
```python
score = evaluate_summaries_pegasus(dataset_samsum["test"], rouge_metric, model, tokenizer, column_text="dialogue", column_summary="summary", batch_size=8)
rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)
pd.DataFrame(rouge_dict, index=["pegasus"])
```
Kod açıklamaları:

* `evaluate_summaries_pegasus`: Test kümesi üzerinde ROUGE değerlendirmesi yapar.
* `rouge_dict`: ROUGE skorlarını bir sözlüğe dönüştürür.
* `pd.DataFrame`: ROUGE skorlarını bir DataFrame'e dönüştürür.

## Modeli Eğitme (Training the Model)

Modeli SAMSum veri kümesi üzerinde eğitelim:
```python
training_args = TrainingArguments(
    output_dir='pegasus-samsum',
    num_train_epochs=1,
    warmup_steps=500,
    per_device_train_batch_size=1,
    per_device_eval_batch_size=1,
    weight_decay=0.01,
    logging_steps=10,
    push_to_hub=True,
    evaluation_strategy='steps',
    eval_steps=500,
    save_steps=1e6,
    gradient_accumulation_steps=16
)
trainer = Trainer(
    model=model,
    args=training_args,
    tokenizer=tokenizer,
    data_collator=seq2seq_data_collator,
    train_dataset=dataset_samsum_pt["train"],
    eval_dataset=dataset_samsum_pt["validation"]
)
trainer.train()
```
Kod açıklamaları:

* `TrainingArguments`: Eğitim argümanlarını tanımlar.
* `Trainer`: Modeli eğitmek için bir Trainer nesnesi oluşturur.
* `trainer.train()`: Modeli eğitir.

## Eğitilmiş Modeli Değerlendirme (Evaluating the Trained Model)

Eğitilmiş modelin performansını değerlendirelim:
```python
score = evaluate_summaries_pegasus(dataset_samsum["test"], rouge_metric, trainer.model, tokenizer, batch_size=2, column_text="dialogue", column_summary="summary")
rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)
pd.DataFrame(rouge_dict, index=[f"pegasus"])
```
Kod açıklamaları:

* `evaluate_summaries_pegasus`: Test kümesi üzerinde ROUGE değerlendirmesi yapar.
* `rouge_dict`: ROUGE skorlarını bir sözlüğe dönüştürür.
* `pd.DataFrame`: ROUGE skorlarını bir DataFrame'e dönüştürür.

## Özel Girişler Üzerinde Modeli Test Etme (Testing the Model on Custom Inputs)

Modeli özel girişler üzerinde test edelim:
```python
custom_dialogue = """Thom: Hi guys, have you heard of transformers? Lewis: Yes, I used them recently! Leandro: Indeed, there is a great library by Hugging Face. Thom: I know, I helped build it ;) Lewis: Cool, maybe we should write a book about it. What do you think? Leandro: Great idea, how hard can it be?! Thom: I am in! Lewis: Awesome, let's do it together!"""
print(pipe(custom_dialogue, **gen_kwargs)[0]["summary_text"])
```
Kod açıklamaları:

* `custom_dialogue`: Özel bir diyalog tanımlar.
* `pipe(custom_dialogue, **gen_kwargs)`: Diyalogu özetler.
* `print`: Özeti yazdırır.

---

## Conclusion

# Metin Özetleme Zorlukları ve Değerlendirme Metrikleri (Text Summarization Challenges and Evaluation Metrics)

Metin özetleme (Text Summarization), duygu analizi (Sentiment Analysis), adlandırılmış varlık tanıma (Named Entity Recognition) veya soru cevaplama (Question Answering) gibi sınıflandırma görevleri olarak çerçevelenebilen diğer görevlere kıyasla bazı benzersiz zorluklar ortaya koyar. Geleneksel metrikler (Conventional Metrics) gibi doğruluk (Accuracy), oluşturulan metnin kalitesini yansıtmaz. 

# Değerlendirme Metrikleri (Evaluation Metrics)

BLEU ve ROUGE metrikleri, oluşturulan metinleri daha iyi değerlendirebilir; ancak, insan yargısı (Human Judgment) en iyi ölçüt olmaya devam etmektedir.

# Uzun Belgeleri Özetleme (Summarizing Long Documents)

Özetleme modelleriyle (Summarization Models) çalışırken ortaya çıkan ortak bir soru, modelin bağlam uzunluğundan (Context Length) daha uzun olan belgelerin nasıl özetlenebileceğidir. Ne yazık ki, bu sorunu çözmek için tek bir strateji yoktur ve bugüne kadar bu, hala açık ve aktif bir araştırma sorusudur (Open Research Question). Örneğin, OpenAI tarafından yapılan son çalışmalar, özetlemeyi uzun belgeler üzerinde özyinelemeli (Recursively) olarak uygulayarak ve insan geri bildirimlerini (Human Feedback) kullanarak nasıl ölçeklendirebileceğini gösterdi.

# Kod Kullanımı (Code Usage)

Bu metinde kod örneği bulunmamaktadır.

# İlgili Teknik Terimler (Related Technical Terms)

- Metin Özetleme (Text Summarization)
- Duygu Analizi (Sentiment Analysis)
- Adlandırılmış Varlık Tanıma (Named Entity Recognition)
- Soru Cevaplama (Question Answering)
- Doğruluk (Accuracy)
- BLEU ve ROUGE metrikleri (BLEU and ROUGE Metrics)
- İnsan Yargısı (Human Judgment)
- Özetleme Modelleri (Summarization Models)
- Bağlam Uzunluğu (Context Length)
- Özyinelemeli (Recursively)
- İnsan Geri Bildirimleri (Human Feedback)

# Sonraki Adımlar (Next Steps)

Bir sonraki bölümde, bir metin pasajına (Text Passage) dayalı olarak bir soruya cevap verme görevi olan soru cevaplama (Question Answering) görevini inceleyeceğiz. Özetlemenin aksine, bu görevde uzun veya birçok belgeyle başa çıkmak için iyi stratejiler mevcuttur ve size soru cevaplama işlemini binlerce belgeye nasıl ölçeklendirebileceğinizi göstereceğiz.

---

